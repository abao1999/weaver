{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/share/DJC',\n",
       " '/usr/local/lib',\n",
       " '/storage/user/abao/weaver2/notebooks',\n",
       " '/usr/lib/python36.zip',\n",
       " '/usr/lib/python3.6',\n",
       " '/usr/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/storage/user/abao/.local/lib/python3.6/site-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
       " '/tmp/tmpopl8xlcn',\n",
       " '../',\n",
       " '../',\n",
       " '../']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "if \"../\" not in sys.path:\n",
    "    sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from importlib import import_module\n",
    "import ast\n",
    "from utils.logger import _logger\n",
    "from utils.dataset import SimpleIterDataset\n",
    "from utils.nn.tools import train, evaluate\n",
    "\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Hyperparameters and File Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = \"../data/ak8_points_pf_sv_hww_ptmasswgt_h5.yaml\"\n",
    "data_train = \"/data/shared/abao/DNNTuples/train/*.h5\"\n",
    "data_test = []\n",
    "data_fraction = 1\n",
    "file_fraction = 1\n",
    "fetch_by_files = True\n",
    "fetch_step = 10\n",
    "train_val_split = 0.8\n",
    "demo = False\n",
    "lr_finder = None\n",
    "network_config = \"../networks/particle_net_pf_sv.py\"\n",
    "network_option = []\n",
    "model_prefix = \"../models/testh5\"\n",
    "num_epochs = 20\n",
    "optimizer = \"ranger\"\n",
    "load_epoch = None\n",
    "start_lr = 2e-2\n",
    "lr_steps = '10,20'\n",
    "batch_size = 64\n",
    "use_amp = False\n",
    "gpus = \"0,2,3,4,5\"\n",
    "num_workers = 4\n",
    "predict = False\n",
    "# predict_output = \n",
    "export_onnx = None\n",
    "# io_test = False\n",
    "\n",
    "# training/testing mode\n",
    "training_mode = not predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Device (GPU if Possible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "if gpus:\n",
    "    gpus = [int(i) for i in gpus.split(',')]\n",
    "    print(gpus,gpus[0])\n",
    "    dev = torch.device(gpus[0])\n",
    "else:\n",
    "    gpus = None\n",
    "    dev = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "if training_mode:\n",
    "    filelist = sorted(sum([glob.glob(f) for f in data_train], []))\n",
    "    # np.random.seed(1)\n",
    "    np.random.shuffle(filelist)\n",
    "    if demo:\n",
    "        filelist = filelist[:20]\n",
    "        print(filelist)\n",
    "        data_fraction = 0.1\n",
    "        fetch_step = 0.002\n",
    "    num_workers = min(num_workers, int(len(filelist) * file_fraction))\n",
    "    train_data = SimpleIterDataset(filelist, data_config, for_training=True, load_range_and_fraction=((0, train_val_split), data_fraction),\n",
    "                                   file_fraction=file_fraction, fetch_by_files=fetch_by_files, fetch_step=fetch_step)\n",
    "    val_data = SimpleIterDataset(filelist, data_config, for_training=True, load_range_and_fraction=((train_val_split, 1), data_fraction),\n",
    "                                 file_fraction=file_fraction, fetch_by_files=fetch_by_files, fetch_step=fetch_step)\n",
    "    train_loader = DataLoader(train_data, num_workers=num_workers, batch_size=batch_size, drop_last=True, pin_memory=True)\n",
    "    val_loader = DataLoader(val_data, num_workers=num_workers, batch_size=batch_size, drop_last=True, pin_memory=True)\n",
    "    data_config = train_data.config\n",
    "else:\n",
    "    filelist = sorted(sum([glob.glob(f) for f in data_test], []))\n",
    "    num_workers = min(num_workers, len(filelist))\n",
    "    test_data = SimpleIterDataset(filelist, data_config, for_training=False,\n",
    "                                  load_range_and_fraction=((0, 1), data_fraction),\n",
    "                                  fetch_by_files=True, fetch_step=1)\n",
    "    test_loader = DataLoader(test_data, num_workers=num_workers, batch_size=batch_size, drop_last=False, pin_memory=True)\n",
    "    data_config = test_data.config\n",
    "    print('test loader done ')\n",
    "    print(data_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model (Load Model File)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "network_module = import_module(network_config.replace('.py', '').replace('/', '.'))\n",
    "network_options = {k:ast.literal_eval(v) for k, v in network_option}\n",
    "if export_onnx:\n",
    "    network_options['for_inference'] = True\n",
    "if use_amp:\n",
    "    network_options['use_amp'] = True\n",
    "model, model_info = network_module.get_model(data_config, **network_options)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option to Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to ONNX\n",
    "if export_onnx:\n",
    "    assert(export_onnx.endswith('.onnx'))\n",
    "    model_path = model_prefix\n",
    "    print('Exporting model %s to ONNX' % model_path)\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "    model = model.cpu()\n",
    "    model.eval()\n",
    "\n",
    "    os.makedirs(os.path.dirname(export_onnx), exist_ok=True)\n",
    "    inputs = tuple(torch.ones(model_info['input_shapes'][k], dtype=torch.float32) for k in model_info['input_names'])\n",
    "    torch.onnx.export(model, inputs, export_onnx,\n",
    "                      input_names=model_info['input_names'],\n",
    "                      output_names=model_info['output_names'],\n",
    "                      dynamic_axes=model_info.get('dynamic_axes', None),\n",
    "                      opset_version=11)\n",
    "    print('ONNX model saved to %s', export_onnx)\n",
    "\n",
    "    preprocessing_json = os.path.join(os.path.dirname(export_onnx), 'preprocess.json')\n",
    "    data_config.export_json(preprocessing_json)\n",
    "    print('Preprocessing parameters saved to %s', preprocessing_json)\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: we should always save/load the state_dict of the original model, not the one wrapped by nn.DataParallel\n",
    "# so we do not convert it to nn.DataParallel now\n",
    "model = model.to(dev)\n",
    "\n",
    "if training_mode:\n",
    "    # loss function\n",
    "    try:\n",
    "        loss_func = network_module.get_loss(data_config, **network_options)\n",
    "        print(loss_func)\n",
    "    except AttributeError:\n",
    "        loss_func = torch.nn.CrossEntropyLoss()\n",
    "        print('Loss function not defined in %s. Will use `torch.nn.CrossEntropyLoss()` by default.', network_config)\n",
    "\n",
    "    # optimizer & learning rate\n",
    "    if optimizer == 'adam':\n",
    "        opt = torch.optim.Adam(model.parameters(), lr=start_lr)\n",
    "        if lr_finder is None:\n",
    "            lr_steps = [int(x) for x in lr_steps.split(',')]\n",
    "            scheduler = torch.optim.lr_scheduler.MultiStepLR(opt, milestones=lr_steps, gamma=0.1)\n",
    "    else:\n",
    "        from utils.nn.optimizer.ranger import Ranger\n",
    "        opt = Ranger(model.parameters(), lr=start_lr)\n",
    "        if lr_finder is None:\n",
    "            lr_decay_epochs = max(1, int(num_epochs * 0.3))\n",
    "            lr_decay_rate = 0.01 ** (1. / lr_decay_epochs)\n",
    "            scheduler = torch.optim.lr_scheduler.MultiStepLR(opt, milestones=list(range(num_epochs - lr_decay_epochs, num_epochs)), gamma=lr_decay_rate)\n",
    "\n",
    "    # load previous training and resume if `--load-epoch` is set\n",
    "    if load_epoch is not None:\n",
    "        print('Resume training from epoch %d' % load_epoch)\n",
    "        model_state = torch.load(model_prefix + '_epoch-%d_state.pt' % load_epoch, map_location=dev)\n",
    "        model.load_state_dict(model_state)\n",
    "        opt_state = torch.load(model_prefix + '_epoch-%d_optimizer.pt' % load_epoch, map_location=dev)\n",
    "        opt.load_state_dict(opt_state)\n",
    "\n",
    "    # mutli-gpu\n",
    "    if gpus is not None and len(gpus) > 1:\n",
    "        model = torch.nn.DataParallel(model, device_ids=gpus)  # model becomes `torch.nn.DataParallel` w/ model.module being the orignal `torch.nn.Module`\n",
    "    model = model.to(dev)\n",
    "\n",
    "    # lr finder: keep it after all other setups\n",
    "    if lr_finder is not None:\n",
    "        start_lr, end_lr, num_iter = lr_finder.replace(' ', '').split(',')\n",
    "        from utils.lr_finder import LRFinder\n",
    "        lr_finder = LRFinder(model, opt, loss_func, device=dev, input_names=train_data.config.input_names, label_names=train_data.config.label_names)\n",
    "        lr_finder.range_test(train_loader, start_lr=float(start_lr), end_lr=float(end_lr), num_iter=int(num_iter))\n",
    "        lr_finder.plot(output='lr_finder.png')  # to inspect the loss-learning rate graph\n",
    "        return\n",
    "\n",
    "    if use_amp:\n",
    "        from torch.cuda.amp import GradScaler\n",
    "        scaler = GradScaler()\n",
    "    else:\n",
    "        scaler = None\n",
    "\n",
    "    # training loop\n",
    "    best_valid_acc = 0\n",
    "    acc_vals_validation = np.zeros(num_epochs)\n",
    "    loss_vals_training = np.zeros(num_epochs)\n",
    "    loss_std_training = np.zeros(num_epochs)\n",
    "    loss_vals_validation = np.zeros(num_epochs)\n",
    "    loss_std_validation = np.zeros(num_epochs)\n",
    "    for epoch in range(num_epochs):\n",
    "        if load_epoch is not None:\n",
    "            if epoch <= load_epoch:\n",
    "                continue\n",
    "        print('-' * 50)\n",
    "        print('Epoch #%d training' % epoch)\n",
    "        loss_mean,loss_std = train(model, loss_func, opt, scheduler, train_loader, dev, grad_scaler=scaler)\n",
    "        loss_vals_training[epoch] =loss_mean\n",
    "        loss_std_training[epoch] = loss_std\n",
    "\n",
    "        if model_prefix:\n",
    "            dirname = os.path.dirname(model_prefix)\n",
    "            if dirname and not os.path.exists(dirname):\n",
    "                os.makedirs(dirname)\n",
    "            state_dict = model.module.state_dict() if isinstance(model, torch.nn.DataParallel) else model.state_dict()\n",
    "            torch.save(state_dict, model_prefix + '_epoch-%d_state.pt' % epoch)\n",
    "            torch.save(opt.state_dict(), model_prefix + '_epoch-%d_optimizer.pt' % epoch)\n",
    "\n",
    "        print('Epoch #%d validating' % epoch)\n",
    "        valid_acc,loss_mean,loss_std = evaluate(model, val_loader, dev, loss_func=loss_func)\n",
    "        loss_vals_validation[epoch] =loss_mean\n",
    "        loss_std_validation[epoch] = loss_std\n",
    "        acc_vals_validation[epoch] = valid_acc\n",
    "        if valid_acc > best_valid_acc:\n",
    "            best_valid_acc = valid_acc\n",
    "            if model_prefix:\n",
    "                shutil.copy2(model_prefix + '_epoch-%d_state.pt' % epoch, model_prefix + '_best_acc_state.pt')\n",
    "                torch.save(model, model_prefix + '_best_acc_full.pt')\n",
    "        print('Epoch #%d: Current validation acc: %.5f (best: %.5f)' % (epoch, valid_acc, best_valid_acc))\n",
    "\n",
    "    dirname = os.path.dirname('%s_history/'%model_prefix)\n",
    "    if dirname and not os.path.exists(dirname):\n",
    "        os.makedirs(dirname)\n",
    "\n",
    "    np.save('%s_history/acc_vals_validation.npy'%(model_prefix),acc_vals_validation)\n",
    "    np.save('%s_history/loss_vals_training.npy'%(model_prefix),loss_vals_training)\n",
    "    np.save('%s_history/loss_vals_validation.npy'%(model_prefix),loss_vals_validation)\n",
    "    np.save('%s_history/loss_std_validation.npy'%(model_prefix),loss_std_validation)\n",
    "    np.save('%s_history/loss_std_training.npy'%(model_prefix),loss_std_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not training_mode:\n",
    "    # run prediction\n",
    "    if model_prefix.endswith('.onnx'):\n",
    "        print('Loading model %s for eval' % model_prefix)\n",
    "        from utils.nn.tools import evaluate_onnx\n",
    "        test_acc, scores, labels, observers = evaluate_onnx(model_prefix, test_loader)\n",
    "    else:\n",
    "        model_path = model_prefix if model_prefix.endswith('.pt') else model_prefix + '_best_acc_state.pt'\n",
    "        print('Loading model %s for eval' % model_path)\n",
    "        model.load_state_dict(torch.load(model_path, map_location=dev))\n",
    "        if gpus is not None and len(gpus) > 1:\n",
    "            model = torch.nn.DataParallel(model, device_ids=gpus)\n",
    "        model = model.to(dev)\n",
    "        test_acc, scores, labels, observers = evaluate(model, test_loader, dev, for_training=False)\n",
    "    print('Test acc %.5f' % test_acc)\n",
    "\n",
    "    if predict_output:\n",
    "        os.makedirs(os.path.dirname(predict_output), exist_ok=True)\n",
    "        if predict_output.endswith('.root'):\n",
    "            from utils.data.fileio import _write_root\n",
    "            output = {}\n",
    "            for idx, label_name in enumerate(data_config.label_value):\n",
    "                output[label_name] = (labels[data_config.label_names[0]] == idx)\n",
    "                output['score_' + label_name] = scores[:, idx]\n",
    "            for k, v in labels.items():\n",
    "                if k == data_config.label_names[0]:\n",
    "                    continue\n",
    "                if v.ndim > 1:\n",
    "                    print('Ignoring %s, not a 1d array.', k)\n",
    "                    continue\n",
    "                output[k] = v\n",
    "            for k, v in observers.items():\n",
    "                if v.ndim > 1:\n",
    "                    print('Ignoring %s, not a 1d array.', k)\n",
    "                    continue\n",
    "                output[k] = v\n",
    "            _write_root(predict_output, output)\n",
    "        else:\n",
    "            import awkward\n",
    "            output = {'scores':scores}\n",
    "            output.update(labels)\n",
    "            output.update(observers)\n",
    "\n",
    "            name_remap = {}\n",
    "            arraynames = list(output)\n",
    "            for i in range(len(arraynames)):\n",
    "                for j in range(i + 1, len(arraynames)):\n",
    "                    if arraynames[i].startswith(arraynames[j]):\n",
    "                        name_remap[arraynames[j]] = '%s_%d' % (arraynames[j], len(name_remap))\n",
    "                    if arraynames[j].startswith(arraynames[i]):\n",
    "                        name_remap[arraynames[i]] = '%s_%d' % (arraynames[i], len(name_remap))\n",
    "            print('Renamed the following variables in the output file: %s', str(name_remap))\n",
    "            output = {name_remap[k] if k in name_remap else k: v for k, v in output.items()}\n",
    "\n",
    "            awkward.save(predict_output, output, mode='w')\n",
    "\n",
    "        print('Written output to %s' % predict_output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
